{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import PIL\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, roc_curve, roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from scipy.signal import resample\n",
    "\n",
    "\n",
    "# Our imports\n",
    "from data import WaveletTransform, AFECGDataset, SecondDataset, WrapperDataset\n",
    "import dsp\n",
    "from model.blocks import ConvNet, BRNN, SoftmaxAttention\n",
    "from model.baseline import Baseline\n",
    "from training import train, test\n",
    "import utils\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "testCase = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = SecondDataset(dataset_name, '../data/afdb/', wt=WaveletTransform(resample=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6585/28104 [00:14<00:52, 410.06it/s]"
     ]
    }
   ],
   "source": [
    "# dataset.load(num_records=1)\n",
    "dataset.load('./temp/' + dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_sample = 20\n",
    "total_data_size = len(dataset)\n",
    "print(\"Total data size: \", total_data_size)\n",
    "print(\"Samples with AF: \", dataset.labels.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "power, label = dataset[0]\n",
    "print('Has AF: ', 'Yes' if label == 1 else 'No')\n",
    "\n",
    "signal = power # resample(power, 250)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power, label = dataset[22]\n",
    "print('Has AF: ', 'Yes' if label == 1 else 'No')\n",
    "\n",
    "signal = power # resample(power, 250)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heldout = int(len(dataset) * 0.2)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - heldout, heldout])\n",
    "train_indices = train_dataset.indices\n",
    "test_indices = test_dataset.indices\n",
    "print('[Train] Positive cases = {}'.format((dataset.labels[train_indices] == 1).sum()))\n",
    "print('[Test] Positive cases = {}'.format((dataset.labels[test_indices] == 1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    ConvNet((30, 375), batch=False),\n",
    "    nn.Linear(50, 2)\n",
    ")\n",
    "\n",
    "config = dict(\n",
    "    num_workers=2,\n",
    "    batch_size=30,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    num_epochs=4,\n",
    "    is_notebook=True\n",
    ")\n",
    "\n",
    "train(model, train_dataset, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset.labels[test_dataset.indices]\n",
    "y_pred, test_acc = test(model, test_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "results = pd.DataFrame(classification_report(y_true, y_pred, zero_division=0, output_dict=True)).transpose()\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "auc_score = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = roc_auc_score(y_true, y_pred)\n",
    "print('ROC AUC=%.3f' % (lr_auc))\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Baseline model')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_auc = average_precision_score(y_true, y_pred)\n",
    "print(\"PR AUC:\", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
