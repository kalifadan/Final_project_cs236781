{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import PIL\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, roc_curve, roc_auc_score\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Our imports\n",
    "from data import WaveletTransform, AFECGDataset, SecondDataset, WrapperDataset\n",
    "import dsp\n",
    "from model.blocks import ConvNet, BRNN, SoftmaxAttention\n",
    "from model.baseline import Baseline\n",
    "from training import train, test\n",
    "import utils\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset2 = SecondDataset(dataset_name, '../data/files/')\n",
    "class_weights = dataset2.load('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example, label = dataset2[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_size = len(dataset2)\n",
    "print(\"Total data size: \", total_data_size)\n",
    "print(\"Patients with AF: \", dataset2.labels.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = AFECGDataset(dataset_name, '../data/files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_af, label_af = dataset[0]\n",
    "data_nsr, label_nsr = dataset[1]\n",
    "\n",
    "t = data_nsr[0]\n",
    "utils.show_spectrogram(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_sample = 20\n",
    "total_data_size = len(dataset)\n",
    "print(\"Total data size: \", total_data_size)\n",
    "print(\"Patients with AF: \", dataset.labels.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [dataset[i][0] for i in range(total_data_size)]\n",
    "# labels = [dataset[i][1] for i in range(total_data_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of one ECG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, label = data[0], labels[0]\n",
    "# print('P-signal: ', samples)\n",
    "# print('Has AF: ', 'Yes' if label == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), resample=20)\n",
    "# t = to_wavelet(data[0][0])\n",
    "# image_test = (t * 100 * 255).int() # Simple visualization test\n",
    "# transforms.ToPILImage()(image_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data size is 1397\n",
    "# You can choose the data size \n",
    "data_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = x_train[0][0].float()\n",
    "# encoder_cnn = ConvNet((375, 20))\n",
    "\n",
    "# display(x0.unsqueeze(0).shape)\n",
    "# h = encoder_cnn(x0.unsqueeze(0))\n",
    "# print(h.shape)\n",
    "\n",
    "# test.assertEqual(h.dim(), 2)\n",
    "# test.assertSequenceEqual(h.shape, (1, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(BRNN(50, 50, images_per_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations:\n",
    "\n",
    "* $Y = \\left[ y_1, \\ldots, y_T \\right]$ – the input matrix of size $\\left( N \\times T \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $w_\\mathrm{att}$ – The parameters of the attention model, of size $\\left( N \\times 1 \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $\\alpha$ – The attention weights, given as $\\alpha = \\mathrm{softmax} \\left( w_\\mathrm{att}^T Y \\right)$. This is an element-wise softmax, where the output size of $\\alpha$ is $\\left( 1 \\times T \\right)$\n",
    "\n",
    "* $h_\\mathrm{att}$ – Output of the attention mechanism, given by $h_\\mathrm{att} = Y \\alpha^T$, of size $\\left( N \\times 1 \\right)$, i.e. a vector of $N$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoftmaxAttention(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data1, label1 = dataset[0]\n",
    "utils.show_spectrogram(data1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heldout = int(len(dataset2) * 0.2)\n",
    "train_dataset2, test_dataset2 = torch.utils.data.random_split(dataset2, [len(dataset2) - heldout, heldout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = dataset2.samples[dataset2.labels == 1]\n",
    "data_neg = dataset2.samples[dataset2.labels == 0][:100]\n",
    "labels_pos = dataset2.labels[dataset2.labels == 1]\n",
    "labels_neg = dataset2.labels[dataset2.labels == 0][:100]\n",
    "\n",
    "data = torch.cat([data_pos, data_neg])\n",
    "labels = torch.cat([labels_pos, labels_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_class_weights = torch.tensor(class_weights)[train_dataset2.indices]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    ConvNet(size=(375, 20), batch=False),\n",
    "    nn.Linear(50, 2)\n",
    ")\n",
    "\n",
    "config = dict(\n",
    "    num_workers=8,\n",
    "    batch_size=90,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    class_weights=None,\n",
    "    num_epochs=200,\n",
    "    is_notebook=True\n",
    ")\n",
    "\n",
    "train(model, WrapperDataset(data, labels), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heldout = int(len(dataset) * 0.2)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - heldout, heldout])\n",
    "\n",
    "model = Baseline(add_brnn=False)\n",
    "config = dict(\n",
    "    num_workers=8,\n",
    "    batch_size=90,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    num_epochs=200,\n",
    "\n",
    "#     num_epochs=200,\n",
    "    is_notebook=True\n",
    ")\n",
    "\n",
    "train(model, train_dataset, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset2.labels[test_dataset2.indices]\n",
    "y_pred, test_acc = test(model, test_dataset2, config)\n",
    "print(len(test_dataset2))\n",
    "print(dataset2.labels[test_dataset2.indices].sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(classification_report(y_true, y_pred, zero_division=0, output_dict=True)).transpose()\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "auc_score = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = roc_auc_score(y_true, y_pred)\n",
    "print('ROC AUC=%.3f' % (lr_auc))\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Baseline model')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_auc = average_precision_score(y_true, y_pred)\n",
    "print(\"PR AUC:\", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
