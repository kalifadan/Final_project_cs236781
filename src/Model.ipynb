{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Our imports\n",
    "from data import WaveletTransform, AFECGDataset\n",
    "import dsp\n",
    "from model.blocks import ConvNet, BRNN, SoftmaxAttention\n",
    "from model.baseline import Baseline\n",
    "from training import train\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = AFECGDataset(dataset_name, '../data/files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 249.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 1397 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1397it [00:04, 336.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4165.770053863525 ms\n",
      "Skipped 1397 files which had a backup\n"
     ]
    }
   ],
   "source": [
    "dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 375])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = dataset[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  1397\n"
     ]
    }
   ],
   "source": [
    "images_per_sample = 20\n",
    "total_data_size = len(dataset)\n",
    "print(\"Total data size: \", total_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [dataset[i][0] for i in range(total_data_size)]\n",
    "# labels = [dataset[i][1] for i in range(total_data_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of one ECG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, label = data[0], labels[0]\n",
    "# print('P-signal: ', samples)\n",
    "# print('Has AF: ', 'Yes' if label == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), resample=20)\n",
    "# t = to_wavelet(data[0][0])\n",
    "# image_test = (t * 100 * 255).int() # Simple visualization test\n",
    "# transforms.ToPILImage()(image_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data size is 1397\n",
    "# You can choose the data size \n",
    "data_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = x_train[0][0].float()\n",
    "# encoder_cnn = ConvNet((375, 20))\n",
    "\n",
    "# display(x0.unsqueeze(0).shape)\n",
    "# h = encoder_cnn(x0.unsqueeze(0))\n",
    "# print(h.shape)\n",
    "\n",
    "# test.assertEqual(h.dim(), 2)\n",
    "# test.assertSequenceEqual(h.shape, (1, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRNN(\n",
       "  (bi_rnn): RNN(50, 50, num_layers=20, bidirectional=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(BRNN(50, 50, images_per_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations:\n",
    "\n",
    "* $Y = \\left[ y_1, \\ldots, y_T \\right]$ – the input matrix of size $\\left( N \\times T \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $w_\\mathrm{att}$ – The parameters of the attention model, of size $\\left( N \\times 1 \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $\\alpha$ – The attention weights, given as $\\alpha = \\mathrm{softmax} \\left( w_\\mathrm{att}^T Y \\right)$. This is an element-wise softmax, where the output size of $\\alpha$ is $\\left( 1 \\times T \\right)$\n",
    "\n",
    "* $h_\\mathrm{att}$ – Output of the attention mechanism, given by $h_\\mathrm{att} = Y \\alpha^T$, of size $\\left( N \\times 1 \\right)$, i.e. a vector of $N$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftmaxAttention()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoftmaxAttention(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 20, 375])\n",
      "After CNN:  torch.Size([20, 2, 50])\n",
      "ATT: torch.Size([20, 2, 100])\n",
      "After ATT:  torch.Size([2, 1, 100])\n",
      "After ATT:  tensor([[-4.2561, -6.3109,  1.1911, -0.2955, -5.3390,  0.2070, -3.4266,  2.7582,\n",
      "         -0.6609,  3.2697, -2.5230,  5.5940,  4.1184, -1.4610,  0.0082, -0.2382,\n",
      "         -5.3136,  0.1817, -6.3881, -4.0600, -3.3778, -0.9883,  1.8645,  0.7423,\n",
      "          2.8552, -0.5872,  0.9899,  3.7438, -3.5625, -4.0232,  0.7921,  0.8500,\n",
      "          7.1969,  0.8422, -2.3092, -1.4618,  0.8833, -1.2942, -3.8356, -2.6497,\n",
      "         -1.2535, -0.0089,  4.7178, -0.4363, -0.6325, -1.4977, -3.9815, -4.9241,\n",
      "          2.5366, -0.8858,  4.1725, -3.7541, -2.8154, -1.4812,  3.3012,  0.6719,\n",
      "         -1.6442,  1.9279, -1.7704, -3.0573, -2.9901,  1.5986, -0.8152,  4.9661,\n",
      "         -1.6605,  3.9446, -0.2702,  0.3645,  0.0639, -0.0665, -1.4248, -2.3715,\n",
      "         -0.6283,  4.3758, -1.1104, -1.3440, -2.5410, -1.5677, -1.1338,  2.9932,\n",
      "          1.1986,  5.6360,  1.8488, -5.6310,  0.1440, -2.7417,  2.9429,  2.9081,\n",
      "          4.8899,  3.6974,  1.5739,  2.6965, -6.3986, -3.1627,  4.7783,  3.8508,\n",
      "         -3.9247,  0.5693,  5.3239,  4.3355],\n",
      "        [-4.2559, -6.3105,  1.1904, -0.2958, -5.3387,  0.2074, -3.4265,  2.7581,\n",
      "         -0.6607,  3.2696, -2.5226,  5.5934,  4.1182, -1.4611,  0.0086, -0.2379,\n",
      "         -5.3137,  0.1813, -6.3880, -4.0595, -3.3779, -0.9878,  1.8642,  0.7425,\n",
      "          2.8550, -0.5873,  0.9902,  3.7435, -3.5625, -4.0230,  0.7922,  0.8499,\n",
      "          7.1968,  0.8421, -2.3092, -1.4616,  0.8836, -1.2941, -3.8352, -2.6498,\n",
      "         -1.2538, -0.0091,  4.7175, -0.4363, -0.6326, -1.4975, -3.9814, -4.9237,\n",
      "          2.5365, -0.8853,  4.1724, -3.7539, -2.8154, -1.4811,  3.3014,  0.6716,\n",
      "         -1.6444,  1.9280, -1.7701, -3.0569, -2.9902,  1.5990, -0.8153,  4.9659,\n",
      "         -1.6604,  3.9446, -0.2696,  0.3644,  0.0644, -0.0666, -1.4247, -2.3714,\n",
      "         -0.6283,  4.3754, -1.1103, -1.3442, -2.5408, -1.5674, -1.1340,  2.9930,\n",
      "          1.1985,  5.6356,  1.8488, -5.6308,  0.1441, -2.7415,  2.9427,  2.9080,\n",
      "          4.8897,  3.6968,  1.5739,  2.6965, -6.3982, -3.1624,  4.7781,  3.8505,\n",
      "         -3.9245,  0.5696,  5.3234,  4.3354]], grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[-3.8624,  1.9049],\n",
      "        [-3.8624,  1.9046]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "data1, label1 = dataset[0]\n",
    "data2, label2 = dataset[1]\n",
    "batch_data = torch.cat([data1.unsqueeze(0) * 10, data2.unsqueeze(0) * 10], dim=0)\n",
    "print(batch_data.shape)\n",
    "output = model(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de1ee3148af42d79e2a79c43242edff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=200.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0b497c04ef460b9ecc9f31d4023a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=16.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After CNN:  torch.Size([20, 90, 50])\n",
      "ATT: torch.Size([20, 90, 100])\n",
      "After ATT:  torch.Size([90, 1, 100])\n",
      "After ATT:  tensor([[-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549],\n",
      "        [-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549],\n",
      "        [-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549],\n",
      "        ...,\n",
      "        [-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549],\n",
      "        [-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549],\n",
      "        [-0.0820, -0.0657, -0.0662,  ..., -0.0757, -0.0662,  0.0549]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670],\n",
      "        [-0.0174,  0.1670]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460],\n",
      "        [0.4540, 0.5460]], grad_fn=<SliceBackward>)\n",
      "Labels: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-8025f910e5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/final_project_cs236781/src/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, config)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Backprop and perform optimisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Baseline()\n",
    "config = dict(\n",
    "    num_workers=4,\n",
    "    batch_size=90,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    num_epochs=200,\n",
    "    is_notebook=True\n",
    ")\n",
    "\n",
    "train(model, dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
