{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import posixpath\n",
    "import wfdb\n",
    "import pycwt as wavelet\n",
    "from data import WaveletTransform, AFECGDataset\n",
    "from PIL import Image\n",
    "import dsp\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = AFECGDataset(dataset_name, '../data/files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 493.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 1397 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1397it [00:06, 229.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 6090.325117111206 ms\n",
      "Skipped 1397 files which had a backup\n"
     ]
    }
   ],
   "source": [
    "dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 375])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = dataset[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  1397\n"
     ]
    }
   ],
   "source": [
    "images_per_sample = 20\n",
    "total_data_size = len(dataset)\n",
    "print(\"Total data size: \", total_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [dataset[i][0] for i in range(total_data_size)]\n",
    "# labels = [dataset[i][1] for i in range(total_data_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of one ECG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, label = data[0], labels[0]\n",
    "# print('P-signal: ', samples)\n",
    "# print('Has AF: ', 'Yes' if label == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), resample=20)\n",
    "# t = to_wavelet(data[0][0])\n",
    "# image_test = (t * 100 * 255).int() # Simple visualization test\n",
    "# transforms.ToPILImage()(image_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data size is 1397\n",
    "# You can choose the data size \n",
    "# data_size = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fmt = '../data/new/sample_{}.pt'\n",
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), resample=20)\n",
    "# start = time.time()\n",
    "\n",
    "# sample_count = data_size\n",
    "# transformed_data = []\n",
    "# # transformed_labels= []\n",
    "\n",
    "# skip = 0\n",
    "# print('Preparing {} samples'.format(sample_count))\n",
    "# for sample_idx, sample in tqdm(enumerate(data[:sample_count])):\n",
    "#     wavelets = []\n",
    "#     filepath = fmt.format(sample_idx)\n",
    "    \n",
    "#     if os.path.isfile(filepath):\n",
    "#         # print('Skip {},{}'.format(sample_idx, signal_idx))\n",
    "#         t = torch.load(fmt.format(sample_idx, signal_idx))\n",
    "#         skip += 1\n",
    "#         transformed_data.append(t)\n",
    "#         continue\n",
    "#     # print(sample)\n",
    "#     for signal_idx, signal in enumerate(sample):\n",
    "#         # print(signal)\n",
    "#         # filepath = fmt.format(sample_idx, signal_idx)\n",
    "#         # if os.path.isfile(filepath):\n",
    "#              # print('Skip {},{}'.format(sample_idx, signal_idx))\n",
    "#         #     skip += 1\n",
    "#         #     continue\n",
    "#         wavelets.append(to_wavelet(signal))\n",
    "        \n",
    "#     t = torch.stack(wavelets)\n",
    "#     t = t.unsqueeze(1)\n",
    "#     transformed_data.append(t)\n",
    "    \n",
    "#     torch.save(t, filepath)\n",
    "    \n",
    "# end = time.time()\n",
    "# print('Elapsed time: {} ms'.format(1000 * (end - start)))\n",
    "# print('Skipped {} files'.format(skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test =  train_test_split(transformed_data, labels[:sample_count], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def _calculate_ouput_size(padding, stride, kernel):\n",
    "        n_in = self.width * self.height\n",
    "        pass\n",
    "    \n",
    "    def __init__(self, size, in_channels=1):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.width, self.height = size\n",
    "                \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(2540, 50)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        out = self.layer1(x)\n",
    "        # print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        # print(out.shape)\n",
    "        # out = out.reshape(out.size(0), -1)\n",
    "        out = self.layer3(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer4(out)\n",
    "        # print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=2540, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ConvNet((256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = x_train[0][0].float()\n",
    "# encoder_cnn = ConvNet((375, 20))\n",
    "\n",
    "# display(x0.unsqueeze(0).shape)\n",
    "# h = encoder_cnn(x0.unsqueeze(0))\n",
    "# print(h.shape)\n",
    "\n",
    "# test.assertEqual(h.dim(), 2)\n",
    "# test.assertSequenceEqual(h.shape, (1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = encoder_cnn\n",
    "# num_epochs = 100\n",
    "# total_size = len(x_train)\n",
    "# test.assertEqual(total_size, len(y_train))\n",
    "\n",
    "# # Loss and optimizer\n",
    "# learning_rate = 0.001\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Train the model\n",
    "# total_step = len(x_train)\n",
    "# loss_list = []\n",
    "# acc_list = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     acc = 0\n",
    "#     for idx, (samples, label) in enumerate(zip(x_train, y_train)):\n",
    "#         label = torch.tensor([label]).long()\n",
    "#         for image in samples:\n",
    "            \n",
    "#             # Run the forward pass\n",
    "#             output = model(image.unsqueeze(0).float())\n",
    "#             loss = criterion(output, label)\n",
    "#             loss_list.append(loss.item())\n",
    "            \n",
    "#             # Backprop and perform Adam optimisation\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             # Track the accuracy\n",
    "#             _, predicted = torch.max(output.data, 1)\n",
    "#             correct = (predicted == label).sum().item()\n",
    "#             acc += correct\n",
    "#             print(correct)\n",
    "                        \n",
    "#     acc = acc / (total_size * 20)          \n",
    "#     acc_list.append(acc)\n",
    "#     print('Epoch [{}/{}], Accuracy: {:.2f}%'\n",
    "#           .format(epoch + 1, num_epochs, acc * 100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_gates):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.bi_rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_gates,\n",
    "                                    batch_first=False, bidirectional=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output, hn = self.bi_rnn(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRNN(\n",
       "  (bi_rnn): RNN(50, 50, num_layers=20, bidirectional=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(BRNN(50, 50, images_per_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations:\n",
    "\n",
    "* $Y = \\left[ y_1, \\ldots, y_T \\right]$ – the input matrix of size $\\left( N \\times T \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $w_\\mathrm{att}$ – The parameters of the attention model, of size $\\left( N \\times 1 \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $\\alpha$ – The attention weights, given as $\\alpha = \\mathrm{softmax} \\left( w_\\mathrm{att}^T Y \\right)$. This is an element-wise softmax, where the output size of $\\alpha$ is $\\left( 1 \\times T \\right)$\n",
    "\n",
    "* $h_\\mathrm{att}$ – Output of the attention mechanism, given by $h_\\mathrm{att} = Y \\alpha^T$, of size $\\left( N \\times 1 \\right)$, i.e. a vector of $N$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxAttention(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SoftmaxAttention, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, input_size))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X [T, B, N]\n",
    "        # weight [N x 1]\n",
    "        batch_size = X.size(1)\n",
    "        X = X.transpose(0,1) # (B, T, N)\n",
    "        alignment_scores = X.matmul(self.weight.t())\n",
    "        # print('AS: ', alignment_scores)\n",
    "        # print('wT: ', self.weight.t().shape)\n",
    "        # print('AS: ', alignment_scores.shape)\n",
    "        # alpha [T x 1]\n",
    "        attn_weights = nn.functional.softmax(alignment_scores, dim=0)\n",
    "        # print('X: ', X.shape)\n",
    "        # print('ATT: ', attn_weights.shape)\n",
    "        # print('X: ', X.shape)\n",
    "        # h_att [1 x N]\n",
    "        return torch.bmm(attn_weights.transpose(1, 2), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "        lst = []\n",
    "        for i in range(images_per_sample):\n",
    "            conv = ConvNet((375, 20))\n",
    "            lst.append(conv)\n",
    "            self.add_module('conv{}'.format(i), conv)\n",
    "            \n",
    "        self.cnn_layers = lst\n",
    "        self.brnn = BRNN(50, 50, images_per_sample)\n",
    "        self.attention = SoftmaxAttention(100)\n",
    "        self.fc = nn.Linear(100, 2)\n",
    "\n",
    "\n",
    "    def forward(self, X): \n",
    "        \"\"\"\n",
    "        Perform forward propagation on a batch of data\n",
    "        :param X: A tensor of shape (B, N, W, H) where (W, H) are the image dimensions,\n",
    "        N is the number of images per sample, and B is the batch size\n",
    "        \"\"\"\n",
    "        X = X / X.min()\n",
    "        print('input: ', X.shape)\n",
    "        # print(X[0,0,:].float().unsqueeze(1), X[0,1,:].float().unsqueeze(1))\n",
    "        out = [self.cnn_layers[i](X[:,i,:].float().unsqueeze(1)) for i in range(images_per_sample)]\n",
    "        out = torch.stack(out)\n",
    "        # print('Equal:', out[0][0] == out[0][1])\n",
    "        # print('After CNN: ', out[0][0], out[0][1])\n",
    "        out = self.brnn(out)\n",
    "        print('After BRNN: ', out)\n",
    "        out = self.attention(out.squeeze(1))\n",
    "        out = out.squeeze(1)\n",
    "        print('After ATT: ', out)\n",
    "        out = self.fc(out)\n",
    "        out = out.squeeze(1)\n",
    "        print('After FC: ', out)\n",
    "        return F.softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(Baseline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, label = dataset[0]\n",
    "# label.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8d2f5d9699458e9d0711668f09ad1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.0417,  0.0762, -0.0414,  ...,  0.0536, -0.0721,  0.0999],\n",
      "         [ 0.0702,  0.1158, -0.0165,  ...,  0.0675, -0.0615,  0.1130],\n",
      "         [ 0.1026,  0.0498,  0.0413,  ...,  0.0357,  0.0347,  0.0704],\n",
      "         ...,\n",
      "         [ 0.0612,  0.0786,  0.0089,  ...,  0.0929, -0.0085,  0.0847],\n",
      "         [ 0.1221,  0.0624, -0.0158,  ..., -0.0357, -0.0674,  0.0776],\n",
      "         [ 0.0678,  0.0416, -0.0204,  ...,  0.0850, -0.1619,  0.0984]],\n",
      "\n",
      "        [[-0.0984,  0.1615, -0.0223,  ...,  0.2111, -0.2065, -0.0716],\n",
      "         [-0.0873,  0.1439,  0.0141,  ...,  0.1736, -0.1908, -0.0845],\n",
      "         [-0.0883,  0.2275, -0.0241,  ...,  0.1729, -0.2589, -0.0818],\n",
      "         ...,\n",
      "         [-0.1024,  0.1720, -0.0233,  ...,  0.1502, -0.2705, -0.0110],\n",
      "         [-0.0432,  0.2192, -0.0728,  ...,  0.2080, -0.1755, -0.0554],\n",
      "         [-0.0339,  0.1673,  0.0067,  ...,  0.2640, -0.1051, -0.0943]],\n",
      "\n",
      "        [[-0.0199,  0.3325,  0.1892,  ...,  0.1244, -0.0570,  0.0210],\n",
      "         [-0.0703,  0.3423,  0.1862,  ...,  0.1758, -0.1297,  0.0161],\n",
      "         [-0.0880,  0.2969,  0.1465,  ...,  0.2005, -0.0324,  0.0029],\n",
      "         ...,\n",
      "         [-0.0811,  0.2742,  0.1488,  ...,  0.1564, -0.0843,  0.0410],\n",
      "         [-0.0863,  0.3686,  0.2042,  ...,  0.1243, -0.0135,  0.0387],\n",
      "         [-0.0257,  0.3418,  0.1385,  ...,  0.0667, -0.1490,  0.0130]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1680,  0.2532,  0.1873,  ...,  0.1128, -0.1149,  0.0200],\n",
      "         [ 0.1953,  0.2210,  0.2375,  ...,  0.1416, -0.1541,  0.0287],\n",
      "         [ 0.1625,  0.1805,  0.1906,  ...,  0.1410, -0.1862,  0.0313],\n",
      "         ...,\n",
      "         [ 0.1957,  0.2568,  0.2115,  ...,  0.2451, -0.1944, -0.0636],\n",
      "         [ 0.1453,  0.2831,  0.1305,  ...,  0.1441, -0.1391,  0.0449],\n",
      "         [ 0.1701,  0.1973,  0.1645,  ...,  0.1626, -0.1108,  0.0009]],\n",
      "\n",
      "        [[ 0.2404,  0.2730,  0.2294,  ...,  0.0388, -0.2222,  0.0260],\n",
      "         [ 0.2559,  0.2863,  0.1009,  ...,  0.0552, -0.2243,  0.0945],\n",
      "         [ 0.2550,  0.2347,  0.1283,  ..., -0.0345, -0.1816,  0.1067],\n",
      "         ...,\n",
      "         [ 0.2525,  0.3021,  0.2340,  ...,  0.0250, -0.2082,  0.1263],\n",
      "         [ 0.2255,  0.2900,  0.2138,  ...,  0.0439, -0.1769,  0.1111],\n",
      "         [ 0.2387,  0.2417,  0.2530,  ...,  0.0789, -0.1962,  0.0647]],\n",
      "\n",
      "        [[ 0.2063,  0.3751,  0.1193,  ...,  0.0318, -0.2429,  0.0717],\n",
      "         [ 0.1812,  0.3257,  0.1756,  ...,  0.0708, -0.2095,  0.0899],\n",
      "         [ 0.1664,  0.3656,  0.0823,  ...,  0.0292, -0.2235,  0.0860],\n",
      "         ...,\n",
      "         [ 0.1852,  0.3573,  0.1441,  ...,  0.0543, -0.2193,  0.0817],\n",
      "         [ 0.1776,  0.3631,  0.1636,  ...,  0.0701, -0.2760,  0.0839],\n",
      "         [ 0.1832,  0.3477,  0.1558,  ...,  0.0579, -0.2227,  0.0185]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.0341,  0.0586,  0.0321,  ...,  0.0252, -0.0283,  0.0154],\n",
      "        [ 0.0373,  0.0601,  0.0309,  ...,  0.0242, -0.0259,  0.0150],\n",
      "        [ 0.0380,  0.0583,  0.0319,  ...,  0.0247, -0.0252,  0.0136],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0579,  0.0320,  ...,  0.0285, -0.0308,  0.0174],\n",
      "        [ 0.0422,  0.0659,  0.0310,  ...,  0.0332, -0.0310,  0.0139],\n",
      "        [ 0.0383,  0.0595,  0.0323,  ...,  0.0303, -0.0279,  0.0137]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[-0.0703,  0.0488],\n",
      "        [-0.0689,  0.0486],\n",
      "        [-0.0700,  0.0507],\n",
      "        [-0.0695,  0.0514],\n",
      "        [-0.0699,  0.0503],\n",
      "        [-0.0693,  0.0477],\n",
      "        [-0.0702,  0.0497],\n",
      "        [-0.0701,  0.0504],\n",
      "        [-0.0710,  0.0515],\n",
      "        [-0.0697,  0.0528],\n",
      "        [-0.0694,  0.0497],\n",
      "        [-0.0689,  0.0527],\n",
      "        [-0.0700,  0.0519],\n",
      "        [-0.0699,  0.0501],\n",
      "        [-0.0712,  0.0474],\n",
      "        [-0.0706,  0.0510],\n",
      "        [-0.0697,  0.0474],\n",
      "        [-0.0703,  0.0530],\n",
      "        [-0.0687,  0.0519],\n",
      "        [-0.0700,  0.0510],\n",
      "        [-0.0698,  0.0521],\n",
      "        [-0.0701,  0.0488],\n",
      "        [-0.0692,  0.0501],\n",
      "        [-0.0694,  0.0521],\n",
      "        [-0.0686,  0.0506],\n",
      "        [-0.0691,  0.0540],\n",
      "        [-0.0706,  0.0517],\n",
      "        [-0.0696,  0.0517],\n",
      "        [-0.0704,  0.0543],\n",
      "        [-0.0715,  0.0505],\n",
      "        [-0.0699,  0.0506],\n",
      "        [-0.0696,  0.0527],\n",
      "        [-0.0702,  0.0522],\n",
      "        [-0.0682,  0.0510],\n",
      "        [-0.0695,  0.0512],\n",
      "        [-0.0707,  0.0511],\n",
      "        [-0.0689,  0.0483],\n",
      "        [-0.0682,  0.0510],\n",
      "        [-0.0698,  0.0521],\n",
      "        [-0.0702,  0.0514],\n",
      "        [-0.0705,  0.0533],\n",
      "        [-0.0703,  0.0495],\n",
      "        [-0.0699,  0.0503],\n",
      "        [-0.0695,  0.0497],\n",
      "        [-0.0694,  0.0536],\n",
      "        [-0.0699,  0.0497],\n",
      "        [-0.0690,  0.0481],\n",
      "        [-0.0712,  0.0513],\n",
      "        [-0.0698,  0.0519],\n",
      "        [-0.0690,  0.0516],\n",
      "        [-0.0709,  0.0526],\n",
      "        [-0.0694,  0.0486],\n",
      "        [-0.0692,  0.0492],\n",
      "        [-0.0703,  0.0494],\n",
      "        [-0.0688,  0.0502],\n",
      "        [-0.0703,  0.0513],\n",
      "        [-0.0686,  0.0521],\n",
      "        [-0.0691,  0.0508],\n",
      "        [-0.0702,  0.0526],\n",
      "        [-0.0702,  0.0524],\n",
      "        [-0.0688,  0.0476],\n",
      "        [-0.0695,  0.0518],\n",
      "        [-0.0701,  0.0526],\n",
      "        [-0.0696,  0.0507],\n",
      "        [-0.0704,  0.0520],\n",
      "        [-0.0697,  0.0499],\n",
      "        [-0.0705,  0.0523],\n",
      "        [-0.0697,  0.0534],\n",
      "        [-0.0683,  0.0492],\n",
      "        [-0.0688,  0.0503],\n",
      "        [-0.0695,  0.0531],\n",
      "        [-0.0685,  0.0533],\n",
      "        [-0.0705,  0.0494],\n",
      "        [-0.0700,  0.0501],\n",
      "        [-0.0692,  0.0501],\n",
      "        [-0.0703,  0.0493],\n",
      "        [-0.0691,  0.0485],\n",
      "        [-0.0705,  0.0546],\n",
      "        [-0.0703,  0.0513],\n",
      "        [-0.0673,  0.0496],\n",
      "        [-0.0694,  0.0506],\n",
      "        [-0.0697,  0.0494],\n",
      "        [-0.0683,  0.0505],\n",
      "        [-0.0696,  0.0506],\n",
      "        [-0.0688,  0.0486],\n",
      "        [-0.0711,  0.0526],\n",
      "        [-0.0697,  0.0507],\n",
      "        [-0.0703,  0.0472],\n",
      "        [-0.0665,  0.0498],\n",
      "        [-0.0696,  0.0519]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miki/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.4703, 0.5297],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4698, 0.5302],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4708, 0.5292],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4704, 0.5296],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4708, 0.5292],\n",
      "        [0.4692, 0.5308],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4698, 0.5302],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4697, 0.5303],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4695, 0.5305],\n",
      "        [0.4697, 0.5303],\n",
      "        [0.4689, 0.5311],\n",
      "        [0.4695, 0.5305],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4695, 0.5305],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4691, 0.5309],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4692, 0.5308],\n",
      "        [0.4705, 0.5295],\n",
      "        [0.4704, 0.5296],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4709, 0.5291],\n",
      "        [0.4697, 0.5303],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4693, 0.5307],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4694, 0.5306],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4702, 0.5298],\n",
      "        [0.4701, 0.5299],\n",
      "        [0.4706, 0.5294],\n",
      "        [0.4688, 0.5312],\n",
      "        [0.4696, 0.5304],\n",
      "        [0.4708, 0.5292],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4703, 0.5297],\n",
      "        [0.4700, 0.5300],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4691, 0.5309],\n",
      "        [0.4699, 0.5301],\n",
      "        [0.4707, 0.5293],\n",
      "        [0.4710, 0.5290],\n",
      "        [0.4696, 0.5304]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
      "Prediction: tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0])\n",
      "Correct: 43\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.0902, -0.1742, -0.1040,  ..., -0.1052, -0.5209,  0.1993],\n",
      "         [ 0.0888, -0.1752, -0.1045,  ..., -0.1070, -0.5212,  0.1992],\n",
      "         [ 0.0891, -0.1752, -0.1062,  ..., -0.1044, -0.5214,  0.1974],\n",
      "         ...,\n",
      "         [ 0.0914, -0.1741, -0.1030,  ..., -0.1052, -0.5211,  0.1995],\n",
      "         [ 0.0910, -0.1742, -0.1050,  ..., -0.1026, -0.5226,  0.1963],\n",
      "         [ 0.0890, -0.1743, -0.1030,  ..., -0.1040, -0.5209,  0.2000]],\n",
      "\n",
      "        [[ 0.1008, -0.2268, -0.0563,  ...,  0.0336, -0.5782,  0.1447],\n",
      "         [ 0.1001, -0.2263, -0.0565,  ...,  0.0316, -0.5773,  0.1436],\n",
      "         [ 0.1018, -0.2253, -0.0526,  ...,  0.0348, -0.5784,  0.1430],\n",
      "         ...,\n",
      "         [ 0.1013, -0.2251, -0.0542,  ...,  0.0313, -0.5782,  0.1462],\n",
      "         [ 0.1028, -0.2263, -0.0549,  ...,  0.0350, -0.5785,  0.1445],\n",
      "         [ 0.1028, -0.2272, -0.0560,  ...,  0.0328, -0.5785,  0.1453]],\n",
      "\n",
      "        [[ 0.2241, -0.0063,  0.1204,  ..., -0.0906, -0.5986,  0.0958],\n",
      "         [ 0.2240, -0.0055,  0.1201,  ..., -0.0898, -0.5968,  0.0923],\n",
      "         [ 0.2241, -0.0047,  0.1212,  ..., -0.0905, -0.5969,  0.0935],\n",
      "         ...,\n",
      "         [ 0.2236, -0.0070,  0.1203,  ..., -0.0930, -0.5996,  0.0962],\n",
      "         [ 0.2264, -0.0060,  0.1193,  ..., -0.0913, -0.5976,  0.0952],\n",
      "         [ 0.2246, -0.0061,  0.1194,  ..., -0.0911, -0.5967,  0.0955]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1993,  0.0280,  0.2567,  ..., -0.1658, -0.6246,  0.1020],\n",
      "         [ 0.1982,  0.0289,  0.2580,  ..., -0.1628, -0.6243,  0.1016],\n",
      "         [ 0.2010,  0.0261,  0.2551,  ..., -0.1629, -0.6248,  0.1031],\n",
      "         ...,\n",
      "         [ 0.2008,  0.0283,  0.2561,  ..., -0.1618, -0.6227,  0.1015],\n",
      "         [ 0.2007,  0.0280,  0.2584,  ..., -0.1636, -0.6233,  0.1020],\n",
      "         [ 0.2009,  0.0289,  0.2559,  ..., -0.1663, -0.6230,  0.1014]],\n",
      "\n",
      "        [[ 0.2570,  0.0158,  0.2953,  ...,  0.0306, -0.6134, -0.0565],\n",
      "         [ 0.2560,  0.0132,  0.2964,  ...,  0.0293, -0.6127, -0.0567],\n",
      "         [ 0.2595,  0.0123,  0.2941,  ...,  0.0276, -0.6118, -0.0586],\n",
      "         ...,\n",
      "         [ 0.2569,  0.0175,  0.2976,  ...,  0.0291, -0.6106, -0.0567],\n",
      "         [ 0.2574,  0.0141,  0.2930,  ...,  0.0300, -0.6137, -0.0558],\n",
      "         [ 0.2570,  0.0148,  0.2940,  ...,  0.0294, -0.6139, -0.0566]],\n",
      "\n",
      "        [[ 0.1800,  0.1637,  0.4269,  ..., -0.0187, -0.2816, -0.0255],\n",
      "         [ 0.1802,  0.1660,  0.4257,  ..., -0.0178, -0.2808, -0.0255],\n",
      "         [ 0.1799,  0.1663,  0.4250,  ..., -0.0183, -0.2820, -0.0265],\n",
      "         ...,\n",
      "         [ 0.1816,  0.1646,  0.4280,  ..., -0.0134, -0.2822, -0.0260],\n",
      "         [ 0.1822,  0.1655,  0.4255,  ..., -0.0161, -0.2813, -0.0270],\n",
      "         [ 0.1834,  0.1646,  0.4256,  ..., -0.0169, -0.2817, -0.0257]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.0451,  0.0032,  0.0428,  ..., -0.0123, -0.1325,  0.0168],\n",
      "        [ 0.0450,  0.0032,  0.0428,  ..., -0.0123, -0.1324,  0.0167],\n",
      "        [ 0.0451,  0.0032,  0.0427,  ..., -0.0125, -0.1326,  0.0166],\n",
      "        ...,\n",
      "        [ 0.0451,  0.0033,  0.0428,  ..., -0.0123, -0.1325,  0.0167],\n",
      "        [ 0.0451,  0.0032,  0.0427,  ..., -0.0123, -0.1325,  0.0167],\n",
      "        [ 0.0451,  0.0032,  0.0428,  ..., -0.0123, -0.1325,  0.0168]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1214, -0.2185],\n",
      "        [ 0.1215, -0.2187],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1211, -0.2185],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1211, -0.2183],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2188],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1214, -0.2188],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1215, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1216, -0.2189],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1212, -0.2186],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1212, -0.2184],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1212, -0.2184],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1211, -0.2184],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1215, -0.2187],\n",
      "        [ 0.1211, -0.2183],\n",
      "        [ 0.1212, -0.2185],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2185],\n",
      "        [ 0.1214, -0.2186],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1214, -0.2187],\n",
      "        [ 0.1215, -0.2188],\n",
      "        [ 0.1212, -0.2184],\n",
      "        [ 0.1213, -0.2186],\n",
      "        [ 0.1213, -0.2185],\n",
      "        [ 0.1213, -0.2186]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5840, 0.4160],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5843, 0.4157],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158],\n",
      "        [0.5841, 0.4159],\n",
      "        [0.5842, 0.4158]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0])\n",
      "Correct: 42\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.1352, -0.0148, -0.0303,  ..., -0.3810, -0.4215,  0.3053],\n",
      "         [ 0.1354, -0.0145, -0.0312,  ..., -0.3814, -0.4218,  0.3046],\n",
      "         [ 0.1361, -0.0148, -0.0318,  ..., -0.3816, -0.4216,  0.3051],\n",
      "         ...,\n",
      "         [ 0.1354, -0.0156, -0.0324,  ..., -0.3812, -0.4237,  0.3058],\n",
      "         [ 0.1353, -0.0151, -0.0309,  ..., -0.3810, -0.4228,  0.3060],\n",
      "         [ 0.1352, -0.0144, -0.0296,  ..., -0.3806, -0.4213,  0.3049]],\n",
      "\n",
      "        [[ 0.1392,  0.0480,  0.0644,  ..., -0.3330, -0.5081,  0.2452],\n",
      "         [ 0.1377,  0.0478,  0.0629,  ..., -0.3319, -0.5100,  0.2449],\n",
      "         [ 0.1391,  0.0481,  0.0635,  ..., -0.3327, -0.5092,  0.2450],\n",
      "         ...,\n",
      "         [ 0.1394,  0.0477,  0.0633,  ..., -0.3308, -0.5100,  0.2456],\n",
      "         [ 0.1395,  0.0472,  0.0638,  ..., -0.3318, -0.5089,  0.2460],\n",
      "         [ 0.1394,  0.0481,  0.0640,  ..., -0.3328, -0.5088,  0.2453]],\n",
      "\n",
      "        [[ 0.2775,  0.2534,  0.2077,  ..., -0.4362, -0.5384,  0.2180],\n",
      "         [ 0.2793,  0.2535,  0.2078,  ..., -0.4354, -0.5388,  0.2179],\n",
      "         [ 0.2783,  0.2522,  0.2074,  ..., -0.4351, -0.5403,  0.2178],\n",
      "         ...,\n",
      "         [ 0.2793,  0.2519,  0.2074,  ..., -0.4360, -0.5377,  0.2174],\n",
      "         [ 0.2791,  0.2527,  0.2078,  ..., -0.4352, -0.5387,  0.2180],\n",
      "         [ 0.2784,  0.2528,  0.2073,  ..., -0.4351, -0.5394,  0.2176]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3005,  0.2864,  0.2828,  ..., -0.4901, -0.5547,  0.1755],\n",
      "         [ 0.3003,  0.2860,  0.2831,  ..., -0.4905, -0.5545,  0.1761],\n",
      "         [ 0.3000,  0.2859,  0.2827,  ..., -0.4908, -0.5554,  0.1753],\n",
      "         ...,\n",
      "         [ 0.3000,  0.2864,  0.2822,  ..., -0.4906, -0.5547,  0.1755],\n",
      "         [ 0.2987,  0.2861,  0.2825,  ..., -0.4904, -0.5552,  0.1770],\n",
      "         [ 0.2999,  0.2865,  0.2829,  ..., -0.4910, -0.5547,  0.1763]],\n",
      "\n",
      "        [[ 0.3175,  0.2581,  0.2861,  ..., -0.3697, -0.5137,  0.0144],\n",
      "         [ 0.3168,  0.2573,  0.2862,  ..., -0.3705, -0.5138,  0.0153],\n",
      "         [ 0.3172,  0.2587,  0.2854,  ..., -0.3706, -0.5138,  0.0162],\n",
      "         ...,\n",
      "         [ 0.3163,  0.2591,  0.2861,  ..., -0.3707, -0.5134,  0.0159],\n",
      "         [ 0.3167,  0.2582,  0.2857,  ..., -0.3722, -0.5120,  0.0168],\n",
      "         [ 0.3158,  0.2591,  0.2863,  ..., -0.3716, -0.5137,  0.0162]],\n",
      "\n",
      "        [[ 0.2209,  0.3332,  0.3733,  ..., -0.3205, -0.2964,  0.0761],\n",
      "         [ 0.2208,  0.3329,  0.3729,  ..., -0.3204, -0.2965,  0.0757],\n",
      "         [ 0.2198,  0.3323,  0.3728,  ..., -0.3206, -0.2963,  0.0755],\n",
      "         ...,\n",
      "         [ 0.2206,  0.3323,  0.3738,  ..., -0.3199, -0.2957,  0.0751],\n",
      "         [ 0.2194,  0.3319,  0.3737,  ..., -0.3199, -0.2959,  0.0749],\n",
      "         [ 0.2205,  0.3317,  0.3725,  ..., -0.3208, -0.2963,  0.0749]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.0650,  0.0563,  0.0549,  ..., -0.0955, -0.1199,  0.0427],\n",
      "        [ 0.0650,  0.0563,  0.0549,  ..., -0.0956, -0.1200,  0.0427],\n",
      "        [ 0.0649,  0.0563,  0.0549,  ..., -0.0956, -0.1199,  0.0427],\n",
      "        ...,\n",
      "        [ 0.0649,  0.0563,  0.0549,  ..., -0.0956, -0.1199,  0.0427],\n",
      "        [ 0.0650,  0.0563,  0.0549,  ..., -0.0956, -0.1199,  0.0428],\n",
      "        [ 0.0649,  0.0563,  0.0549,  ..., -0.0956, -0.1199,  0.0427]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.2581, -0.3375],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2580, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2580, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2580, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2580, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2580, -0.3375],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2580, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3375],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2581, -0.3376],\n",
      "        [ 0.2582, -0.3377]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6446, 0.3554],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.6447, 0.3553]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "Correct: 55\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2746,  0.3535,  0.0903,  ..., -0.7603, -0.4320,  0.7797],\n",
      "         [ 0.2746,  0.3538,  0.0899,  ..., -0.7605, -0.4323,  0.7798],\n",
      "         [ 0.2749,  0.3536,  0.0903,  ..., -0.7604, -0.4322,  0.7797],\n",
      "         ...,\n",
      "         [ 0.2747,  0.3539,  0.0903,  ..., -0.7603, -0.4322,  0.7797],\n",
      "         [ 0.2743,  0.3537,  0.0900,  ..., -0.7602, -0.4324,  0.7797],\n",
      "         [ 0.2744,  0.3540,  0.0901,  ..., -0.7606, -0.4319,  0.7798]],\n",
      "\n",
      "        [[ 0.3380,  0.6847,  0.3308,  ..., -0.7711, -0.5673,  0.7948],\n",
      "         [ 0.3377,  0.6851,  0.3308,  ..., -0.7711, -0.5676,  0.7948],\n",
      "         [ 0.3380,  0.6851,  0.3309,  ..., -0.7712, -0.5673,  0.7947],\n",
      "         ...,\n",
      "         [ 0.3377,  0.6851,  0.3309,  ..., -0.7711, -0.5674,  0.7947],\n",
      "         [ 0.3381,  0.6848,  0.3308,  ..., -0.7710, -0.5673,  0.7947],\n",
      "         [ 0.3379,  0.6851,  0.3308,  ..., -0.7713, -0.5676,  0.7947]],\n",
      "\n",
      "        [[ 0.4726,  0.7897,  0.4618,  ..., -0.8128, -0.5979,  0.7973],\n",
      "         [ 0.4726,  0.7900,  0.4617,  ..., -0.8131, -0.5977,  0.7974],\n",
      "         [ 0.4727,  0.7900,  0.4617,  ..., -0.8130, -0.5976,  0.7973],\n",
      "         ...,\n",
      "         [ 0.4729,  0.7899,  0.4619,  ..., -0.8130, -0.5977,  0.7973],\n",
      "         [ 0.4725,  0.7898,  0.4618,  ..., -0.8129, -0.5977,  0.7974],\n",
      "         [ 0.4726,  0.7900,  0.4619,  ..., -0.8131, -0.5977,  0.7974]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5032,  0.7942,  0.4953,  ..., -0.8153, -0.6090,  0.7815],\n",
      "         [ 0.5031,  0.7940,  0.4954,  ..., -0.8152, -0.6090,  0.7816],\n",
      "         [ 0.5032,  0.7941,  0.4953,  ..., -0.8154, -0.6092,  0.7817],\n",
      "         ...,\n",
      "         [ 0.5031,  0.7941,  0.4953,  ..., -0.8153, -0.6090,  0.7816],\n",
      "         [ 0.5031,  0.7942,  0.4951,  ..., -0.8155, -0.6092,  0.7817],\n",
      "         [ 0.5032,  0.7940,  0.4954,  ..., -0.8154, -0.6091,  0.7816]],\n",
      "\n",
      "        [[ 0.5002,  0.7788,  0.4833,  ..., -0.7630, -0.5731,  0.6491],\n",
      "         [ 0.5001,  0.7786,  0.4832,  ..., -0.7629, -0.5728,  0.6490],\n",
      "         [ 0.5000,  0.7790,  0.4829,  ..., -0.7631, -0.5729,  0.6492],\n",
      "         ...,\n",
      "         [ 0.4999,  0.7789,  0.4833,  ..., -0.7630, -0.5730,  0.6492],\n",
      "         [ 0.5000,  0.7790,  0.4831,  ..., -0.7631, -0.5730,  0.6493],\n",
      "         [ 0.4999,  0.7788,  0.4832,  ..., -0.7629, -0.5731,  0.6491]],\n",
      "\n",
      "        [[ 0.4076,  0.7491,  0.5083,  ..., -0.6038, -0.3233,  0.4475],\n",
      "         [ 0.4077,  0.7490,  0.5081,  ..., -0.6036, -0.3231,  0.4472],\n",
      "         [ 0.4074,  0.7491,  0.5081,  ..., -0.6041, -0.3232,  0.4475],\n",
      "         ...,\n",
      "         [ 0.4075,  0.7491,  0.5083,  ..., -0.6039, -0.3232,  0.4474],\n",
      "         [ 0.4072,  0.7491,  0.5081,  ..., -0.6042, -0.3232,  0.4476],\n",
      "         [ 0.4074,  0.7490,  0.5081,  ..., -0.6040, -0.3231,  0.4476]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712],\n",
      "        [ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712],\n",
      "        [ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712],\n",
      "        ...,\n",
      "        [ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712],\n",
      "        [ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712],\n",
      "        [ 0.1061,  0.1699,  0.1033,  ..., -0.1781, -0.1297,  0.1712]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7400],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6300, -0.7400],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6300, -0.7400],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7400],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7400],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6300, -0.7399],\n",
      "        [ 0.6299, -0.7399],\n",
      "        [ 0.6299, -0.7399]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7973, 0.2027],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026],\n",
      "        [0.7974, 0.2026]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n",
      "Correct: 58\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2604,  0.3119,  0.0974,  ..., -0.7936, -0.4887,  0.8426],\n",
      "         [ 0.2604,  0.3118,  0.0974,  ..., -0.7936, -0.4887,  0.8426],\n",
      "         [ 0.2605,  0.3118,  0.0974,  ..., -0.7936, -0.4887,  0.8426],\n",
      "         ...,\n",
      "         [ 0.2605,  0.3118,  0.0974,  ..., -0.7935, -0.4887,  0.8426],\n",
      "         [ 0.2604,  0.3118,  0.0974,  ..., -0.7936, -0.4887,  0.8426],\n",
      "         [ 0.2604,  0.3119,  0.0975,  ..., -0.7936, -0.4887,  0.8426]],\n",
      "\n",
      "        [[ 0.3458,  0.6126,  0.3906,  ..., -0.8227, -0.6030,  0.8620],\n",
      "         [ 0.3458,  0.6125,  0.3906,  ..., -0.8226, -0.6030,  0.8620],\n",
      "         [ 0.3457,  0.6125,  0.3906,  ..., -0.8226, -0.6030,  0.8620],\n",
      "         ...,\n",
      "         [ 0.3458,  0.6125,  0.3906,  ..., -0.8226, -0.6029,  0.8620],\n",
      "         [ 0.3458,  0.6125,  0.3906,  ..., -0.8226, -0.6030,  0.8620],\n",
      "         [ 0.3458,  0.6125,  0.3906,  ..., -0.8226, -0.6030,  0.8620]],\n",
      "\n",
      "        [[ 0.4718,  0.7376,  0.5458,  ..., -0.8566, -0.6368,  0.8685],\n",
      "         [ 0.4717,  0.7375,  0.5458,  ..., -0.8566, -0.6367,  0.8685],\n",
      "         [ 0.4717,  0.7376,  0.5458,  ..., -0.8566, -0.6367,  0.8685],\n",
      "         ...,\n",
      "         [ 0.4717,  0.7375,  0.5458,  ..., -0.8565, -0.6368,  0.8685],\n",
      "         [ 0.4717,  0.7375,  0.5457,  ..., -0.8566, -0.6367,  0.8685],\n",
      "         [ 0.4718,  0.7376,  0.5458,  ..., -0.8566, -0.6367,  0.8685]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5070,  0.7483,  0.5791,  ..., -0.8563, -0.6441,  0.8535],\n",
      "         [ 0.5070,  0.7483,  0.5792,  ..., -0.8563, -0.6442,  0.8535],\n",
      "         [ 0.5070,  0.7483,  0.5792,  ..., -0.8563, -0.6441,  0.8535],\n",
      "         ...,\n",
      "         [ 0.5070,  0.7484,  0.5792,  ..., -0.8563, -0.6442,  0.8535],\n",
      "         [ 0.5070,  0.7483,  0.5792,  ..., -0.8563, -0.6441,  0.8535],\n",
      "         [ 0.5070,  0.7483,  0.5792,  ..., -0.8563, -0.6441,  0.8535]],\n",
      "\n",
      "        [[ 0.4986,  0.7278,  0.5667,  ..., -0.8067, -0.5929,  0.7350],\n",
      "         [ 0.4985,  0.7278,  0.5667,  ..., -0.8068, -0.5929,  0.7350],\n",
      "         [ 0.4986,  0.7278,  0.5667,  ..., -0.8067, -0.5929,  0.7350],\n",
      "         ...,\n",
      "         [ 0.4986,  0.7279,  0.5667,  ..., -0.8068, -0.5929,  0.7351],\n",
      "         [ 0.4986,  0.7278,  0.5667,  ..., -0.8067, -0.5928,  0.7350],\n",
      "         [ 0.4985,  0.7278,  0.5667,  ..., -0.8067, -0.5929,  0.7350]],\n",
      "\n",
      "        [[ 0.4157,  0.6934,  0.5761,  ..., -0.6328, -0.3614,  0.4970],\n",
      "         [ 0.4157,  0.6934,  0.5762,  ..., -0.6328, -0.3614,  0.4970],\n",
      "         [ 0.4158,  0.6934,  0.5761,  ..., -0.6328, -0.3613,  0.4970],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6934,  0.5762,  ..., -0.6328, -0.3614,  0.4970],\n",
      "         [ 0.4157,  0.6934,  0.5761,  ..., -0.6327, -0.3613,  0.4970],\n",
      "         [ 0.4158,  0.6934,  0.5762,  ..., -0.6328, -0.3613,  0.4970]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870],\n",
      "        [ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870],\n",
      "        [ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870],\n",
      "        ...,\n",
      "        [ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870],\n",
      "        [ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870],\n",
      "        [ 0.1072,  0.1593,  0.1211,  ..., -0.1879, -0.1387,  0.1870]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7754, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983],\n",
      "        [ 0.7754, -0.8982],\n",
      "        [ 0.7755, -0.8983]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579],\n",
      "        [0.8421, 0.1579]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
      "Prediction: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "Correct: 60\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.1878,  0.2440,  0.1326,  ..., -0.6586, -0.3942,  0.7489],\n",
      "         [ 0.1878,  0.2440,  0.1326,  ..., -0.6586, -0.3942,  0.7489],\n",
      "         [ 0.1878,  0.2440,  0.1327,  ..., -0.6586, -0.3942,  0.7489],\n",
      "         ...,\n",
      "         [ 0.1878,  0.2439,  0.1326,  ..., -0.6586, -0.3942,  0.7489],\n",
      "         [ 0.1878,  0.2440,  0.1326,  ..., -0.6586, -0.3942,  0.7489],\n",
      "         [ 0.1878,  0.2440,  0.1326,  ..., -0.6586, -0.3942,  0.7489]],\n",
      "\n",
      "        [[ 0.2254,  0.4467,  0.3346,  ..., -0.6909, -0.4859,  0.7698],\n",
      "         [ 0.2254,  0.4467,  0.3346,  ..., -0.6910, -0.4859,  0.7698],\n",
      "         [ 0.2254,  0.4467,  0.3346,  ..., -0.6909, -0.4858,  0.7698],\n",
      "         ...,\n",
      "         [ 0.2254,  0.4467,  0.3347,  ..., -0.6909, -0.4858,  0.7698],\n",
      "         [ 0.2255,  0.4467,  0.3346,  ..., -0.6909, -0.4859,  0.7698],\n",
      "         [ 0.2254,  0.4467,  0.3346,  ..., -0.6910, -0.4859,  0.7698]],\n",
      "\n",
      "        [[ 0.3369,  0.5988,  0.4934,  ..., -0.7354, -0.5235,  0.7807],\n",
      "         [ 0.3368,  0.5988,  0.4934,  ..., -0.7354, -0.5234,  0.7807],\n",
      "         [ 0.3368,  0.5988,  0.4934,  ..., -0.7354, -0.5235,  0.7806],\n",
      "         ...,\n",
      "         [ 0.3368,  0.5988,  0.4934,  ..., -0.7354, -0.5234,  0.7807],\n",
      "         [ 0.3368,  0.5988,  0.4934,  ..., -0.7354, -0.5235,  0.7807],\n",
      "         [ 0.3368,  0.5988,  0.4934,  ..., -0.7354, -0.5235,  0.7807]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3869,  0.6278,  0.5461,  ..., -0.7315, -0.5302,  0.7376],\n",
      "         [ 0.3869,  0.6278,  0.5461,  ..., -0.7315, -0.5302,  0.7377],\n",
      "         [ 0.3869,  0.6278,  0.5461,  ..., -0.7315, -0.5302,  0.7377],\n",
      "         ...,\n",
      "         [ 0.3869,  0.6279,  0.5461,  ..., -0.7315, -0.5303,  0.7377],\n",
      "         [ 0.3869,  0.6279,  0.5461,  ..., -0.7315, -0.5302,  0.7377],\n",
      "         [ 0.3869,  0.6279,  0.5461,  ..., -0.7315, -0.5303,  0.7377]],\n",
      "\n",
      "        [[ 0.3767,  0.5997,  0.5240,  ..., -0.6589, -0.4763,  0.5879],\n",
      "         [ 0.3767,  0.5998,  0.5240,  ..., -0.6590, -0.4763,  0.5879],\n",
      "         [ 0.3767,  0.5997,  0.5240,  ..., -0.6590, -0.4762,  0.5879],\n",
      "         ...,\n",
      "         [ 0.3767,  0.5998,  0.5240,  ..., -0.6590, -0.4763,  0.5879],\n",
      "         [ 0.3767,  0.5998,  0.5240,  ..., -0.6590, -0.4763,  0.5879],\n",
      "         [ 0.3767,  0.5998,  0.5240,  ..., -0.6590, -0.4763,  0.5879]],\n",
      "\n",
      "        [[ 0.3139,  0.5757,  0.5128,  ..., -0.4708, -0.2918,  0.3920],\n",
      "         [ 0.3139,  0.5757,  0.5128,  ..., -0.4709, -0.2918,  0.3920],\n",
      "         [ 0.3139,  0.5757,  0.5128,  ..., -0.4708, -0.2918,  0.3920],\n",
      "         ...,\n",
      "         [ 0.3139,  0.5758,  0.5129,  ..., -0.4709, -0.2918,  0.3921],\n",
      "         [ 0.3139,  0.5757,  0.5128,  ..., -0.4708, -0.2918,  0.3920],\n",
      "         [ 0.3139,  0.5757,  0.5128,  ..., -0.4709, -0.2918,  0.3921]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.0812,  0.1332,  0.1144,  ..., -0.1607, -0.1159,  0.1667],\n",
      "        [ 0.0812,  0.1331,  0.1144,  ..., -0.1607, -0.1159,  0.1667],\n",
      "        [ 0.0812,  0.1331,  0.1144,  ..., -0.1607, -0.1159,  0.1667],\n",
      "        ...,\n",
      "        [ 0.0812,  0.1332,  0.1144,  ..., -0.1607, -0.1159,  0.1667],\n",
      "        [ 0.0812,  0.1332,  0.1144,  ..., -0.1607, -0.1159,  0.1667],\n",
      "        [ 0.0812,  0.1332,  0.1144,  ..., -0.1607, -0.1159,  0.1667]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960],\n",
      "        [ 0.6846, -0.7960]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853],\n",
      "        [0.8147, 0.1853]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "Prediction: tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
      "Correct: 65\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2739,  0.2974,  0.1356,  ..., -0.8048, -0.5772,  0.8374],\n",
      "         [ 0.2739,  0.2975,  0.1356,  ..., -0.8048, -0.5772,  0.8374],\n",
      "         [ 0.2739,  0.2974,  0.1356,  ..., -0.8048, -0.5772,  0.8374],\n",
      "         ...,\n",
      "         [ 0.2739,  0.2975,  0.1356,  ..., -0.8048, -0.5772,  0.8374],\n",
      "         [ 0.2739,  0.2974,  0.1356,  ..., -0.8048, -0.5772,  0.8374],\n",
      "         [ 0.2739,  0.2974,  0.1356,  ..., -0.8048, -0.5772,  0.8374]],\n",
      "\n",
      "        [[ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584],\n",
      "         [ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584],\n",
      "         [ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584],\n",
      "         ...,\n",
      "         [ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584],\n",
      "         [ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584],\n",
      "         [ 0.4074,  0.5850,  0.4171,  ..., -0.8414, -0.6798,  0.8584]],\n",
      "\n",
      "        [[ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652],\n",
      "         [ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652],\n",
      "         [ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652],\n",
      "         ...,\n",
      "         [ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652],\n",
      "         [ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652],\n",
      "         [ 0.5339,  0.7199,  0.5699,  ..., -0.8703, -0.7131,  0.8652]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436],\n",
      "         [ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436],\n",
      "         [ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436],\n",
      "         ...,\n",
      "         [ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436],\n",
      "         [ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436],\n",
      "         [ 0.5748,  0.7399,  0.6050,  ..., -0.8677, -0.7147,  0.8436]],\n",
      "\n",
      "        [[ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183],\n",
      "         [ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183],\n",
      "         [ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183],\n",
      "         ...,\n",
      "         [ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183],\n",
      "         [ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183],\n",
      "         [ 0.5581,  0.7202,  0.5889,  ..., -0.8162, -0.6535,  0.7183]],\n",
      "\n",
      "        [[ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798],\n",
      "         [ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798],\n",
      "         [ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798],\n",
      "         ...,\n",
      "         [ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798],\n",
      "         [ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798],\n",
      "         [ 0.4800,  0.6851,  0.5797,  ..., -0.6336, -0.4199,  0.4798]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860],\n",
      "        [ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860],\n",
      "        [ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860],\n",
      "        ...,\n",
      "        [ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860],\n",
      "        [ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860],\n",
      "        [ 0.1216,  0.1573,  0.1272,  ..., -0.1908, -0.1554,  0.1860]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699],\n",
      "        [ 0.8485, -0.9699]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396],\n",
      "        [0.8604, 0.1396]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0])\n",
      "Prediction: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0])\n",
      "Correct: 63\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953],\n",
      "         [ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953],\n",
      "         [ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953],\n",
      "         ...,\n",
      "         [ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953],\n",
      "         [ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953],\n",
      "         [ 0.2276,  0.2686,  0.1624,  ..., -0.7359, -0.5190,  0.7953]],\n",
      "\n",
      "        [[ 0.3345,  0.5046,  0.4032,  ..., -0.7782, -0.6124,  0.8188],\n",
      "         [ 0.3345,  0.5045,  0.4032,  ..., -0.7782, -0.6124,  0.8188],\n",
      "         [ 0.3345,  0.5045,  0.4032,  ..., -0.7782, -0.6124,  0.8188],\n",
      "         ...,\n",
      "         [ 0.3345,  0.5045,  0.4032,  ..., -0.7782, -0.6124,  0.8188],\n",
      "         [ 0.3345,  0.5045,  0.4032,  ..., -0.7782, -0.6124,  0.8188],\n",
      "         [ 0.3345,  0.5046,  0.4032,  ..., -0.7782, -0.6124,  0.8188]],\n",
      "\n",
      "        [[ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287],\n",
      "         [ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287],\n",
      "         [ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287],\n",
      "         ...,\n",
      "         [ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287],\n",
      "         [ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287],\n",
      "         [ 0.4582,  0.6526,  0.5605,  ..., -0.8129, -0.6495,  0.8287]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923],\n",
      "         [ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923],\n",
      "         [ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923],\n",
      "         ...,\n",
      "         [ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923],\n",
      "         [ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923],\n",
      "         [ 0.5114,  0.6876,  0.6093,  ..., -0.8065, -0.6484,  0.7923]],\n",
      "\n",
      "        [[ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502],\n",
      "         [ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502],\n",
      "         [ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502],\n",
      "         ...,\n",
      "         [ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502],\n",
      "         [ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502],\n",
      "         [ 0.4927,  0.6643,  0.5889,  ..., -0.7382, -0.5790,  0.6502]],\n",
      "\n",
      "        [[ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4277],\n",
      "         [ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4278],\n",
      "         [ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4278],\n",
      "         ...,\n",
      "         [ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4277],\n",
      "         [ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4278],\n",
      "         [ 0.4249,  0.6319,  0.5680,  ..., -0.5375, -0.3686,  0.4277]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775],\n",
      "        [ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775],\n",
      "        [ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775],\n",
      "        ...,\n",
      "        [ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775],\n",
      "        [ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775],\n",
      "        [ 0.1077,  0.1459,  0.1283,  ..., -0.1778, -0.1424,  0.1775]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460],\n",
      "        [ 0.8304, -0.9460]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448],\n",
      "        [0.8552, 0.1448]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Correct: 75\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509],\n",
      "         [ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509],\n",
      "         [ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509],\n",
      "         ...,\n",
      "         [ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509],\n",
      "         [ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509],\n",
      "         [ 0.2860,  0.3182,  0.2062,  ..., -0.8147, -0.6287,  0.8509]],\n",
      "\n",
      "        [[ 0.4574,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731],\n",
      "         [ 0.4575,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731],\n",
      "         [ 0.4574,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731],\n",
      "         ...,\n",
      "         [ 0.4574,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731],\n",
      "         [ 0.4574,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731],\n",
      "         [ 0.4575,  0.6010,  0.5010,  ..., -0.8538, -0.7202,  0.8731]],\n",
      "\n",
      "        [[ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811],\n",
      "         [ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811],\n",
      "         [ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811],\n",
      "         ...,\n",
      "         [ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811],\n",
      "         [ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811],\n",
      "         [ 0.5895,  0.7369,  0.6520,  ..., -0.8792, -0.7528,  0.8811]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586],\n",
      "         [ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586],\n",
      "         [ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586],\n",
      "         ...,\n",
      "         [ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586],\n",
      "         [ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586],\n",
      "         [ 0.6360,  0.7645,  0.6891,  ..., -0.8737, -0.7520,  0.8586]],\n",
      "\n",
      "        [[ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378],\n",
      "         [ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378],\n",
      "         [ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378],\n",
      "         ...,\n",
      "         [ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378],\n",
      "         [ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378],\n",
      "         [ 0.6170,  0.7456,  0.6714,  ..., -0.8166, -0.6835,  0.7378]],\n",
      "\n",
      "        [[ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847],\n",
      "         [ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847],\n",
      "         [ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847],\n",
      "         ...,\n",
      "         [ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847],\n",
      "         [ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847],\n",
      "         [ 0.5471,  0.7087,  0.6459,  ..., -0.6136, -0.4454,  0.4847]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896],\n",
      "        [ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896],\n",
      "        [ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896],\n",
      "        ...,\n",
      "        [ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896],\n",
      "        [ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896],\n",
      "        [ 0.1346,  0.1628,  0.1457,  ..., -0.1924, -0.1642,  0.1896]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840],\n",
      "        [ 0.9617, -1.0840]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145],\n",
      "        [0.8855, 0.1145]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "Correct: 73\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565],\n",
      "         [ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565],\n",
      "         [ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565],\n",
      "         ...,\n",
      "         [ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565],\n",
      "         [ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565],\n",
      "         [ 0.2928,  0.3281,  0.2421,  ..., -0.8141, -0.6390,  0.8565]],\n",
      "\n",
      "        [[ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789],\n",
      "         [ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789],\n",
      "         [ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789],\n",
      "         ...,\n",
      "         [ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789],\n",
      "         [ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789],\n",
      "         [ 0.4792,  0.6087,  0.5437,  ..., -0.8543, -0.7257,  0.8789]],\n",
      "\n",
      "        [[ 0.6140,  0.7452,  0.6930,  ..., -0.8790, -0.7584,  0.8874],\n",
      "         [ 0.6140,  0.7452,  0.6930,  ..., -0.8790, -0.7584,  0.8874],\n",
      "         [ 0.6140,  0.7452,  0.6930,  ..., -0.8790, -0.7584,  0.8874],\n",
      "         ...,\n",
      "         [ 0.6140,  0.7452,  0.6930,  ..., -0.8790, -0.7584,  0.8874],\n",
      "         [ 0.6140,  0.7452,  0.6930,  ..., -0.8789, -0.7584,  0.8874],\n",
      "         [ 0.6140,  0.7452,  0.6930,  ..., -0.8790, -0.7584,  0.8874]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645],\n",
      "         [ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645],\n",
      "         [ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645],\n",
      "         ...,\n",
      "         [ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645],\n",
      "         [ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645],\n",
      "         [ 0.6634,  0.7767,  0.7315,  ..., -0.8721, -0.7567,  0.8645]],\n",
      "\n",
      "        [[ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454],\n",
      "         [ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454],\n",
      "         [ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454],\n",
      "         ...,\n",
      "         [ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454],\n",
      "         [ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454],\n",
      "         [ 0.6435,  0.7579,  0.7134,  ..., -0.8111, -0.6843,  0.7454]],\n",
      "\n",
      "        [[ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856],\n",
      "         [ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856],\n",
      "         [ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856],\n",
      "         ...,\n",
      "         [ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856],\n",
      "         [ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856],\n",
      "         [ 0.5773,  0.7206,  0.6827,  ..., -0.5974, -0.4459,  0.4856]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911],\n",
      "        [ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911],\n",
      "        [ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911],\n",
      "        ...,\n",
      "        [ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911],\n",
      "        [ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911],\n",
      "        [ 0.1405,  0.1655,  0.1551,  ..., -0.1922, -0.1655,  0.1911]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461],\n",
      "        [ 1.0238, -1.1461]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025],\n",
      "        [0.8975, 0.1025]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Correct: 81\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779],\n",
      "         [ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779],\n",
      "         [ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779],\n",
      "         ...,\n",
      "         [ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779],\n",
      "         [ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779],\n",
      "         [ 0.3299,  0.3576,  0.2870,  ..., -0.8430, -0.6847,  0.8779]],\n",
      "\n",
      "        [[ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991],\n",
      "         [ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991],\n",
      "         [ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991],\n",
      "         ...,\n",
      "         [ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991],\n",
      "         [ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991],\n",
      "         [ 0.5514,  0.6557,  0.6118,  ..., -0.8807, -0.7664,  0.8991]],\n",
      "\n",
      "        [[ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069],\n",
      "         [ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069],\n",
      "         [ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069],\n",
      "         ...,\n",
      "         [ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069],\n",
      "         [ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069],\n",
      "         [ 0.6852,  0.7838,  0.7509,  ..., -0.9015, -0.7963,  0.9069]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891],\n",
      "         [ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891],\n",
      "         [ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891],\n",
      "         ...,\n",
      "         [ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891],\n",
      "         [ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891],\n",
      "         [ 0.7288,  0.8115,  0.7830,  ..., -0.8956, -0.7953,  0.8891]],\n",
      "\n",
      "        [[ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830],\n",
      "         [ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830],\n",
      "         [ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830],\n",
      "         ...,\n",
      "         [ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830],\n",
      "         [ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830],\n",
      "         [ 0.7098,  0.7947,  0.7665,  ..., -0.8395, -0.7257,  0.7830]],\n",
      "\n",
      "        [[ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119],\n",
      "         [ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119],\n",
      "         [ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119],\n",
      "         ...,\n",
      "         [ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119],\n",
      "         [ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119],\n",
      "         [ 0.6473,  0.7572,  0.7337,  ..., -0.6240, -0.4791,  0.5119]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957],\n",
      "        [ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957],\n",
      "        [ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957],\n",
      "        ...,\n",
      "        [ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957],\n",
      "        [ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957],\n",
      "        [ 0.1549,  0.1733,  0.1666,  ..., -0.1972, -0.1737,  0.1957]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434],\n",
      "        [ 1.1176, -1.2434]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862],\n",
      "        [0.9138, 0.0862]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Correct: 79\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "After BRNN:  tensor([[[ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646],\n",
      "         [ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646],\n",
      "         [ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646],\n",
      "         ...,\n",
      "         [ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646],\n",
      "         [ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646],\n",
      "         [ 0.3137,  0.3405,  0.2892,  ..., -0.8195, -0.6623,  0.8646]],\n",
      "\n",
      "        [[ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869],\n",
      "         [ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869],\n",
      "         [ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869],\n",
      "         ...,\n",
      "         [ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869],\n",
      "         [ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869],\n",
      "         [ 0.5278,  0.6230,  0.5988,  ..., -0.8607, -0.7416,  0.8869]],\n",
      "\n",
      "        [[ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957],\n",
      "         [ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957],\n",
      "         [ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957],\n",
      "         ...,\n",
      "         [ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957],\n",
      "         [ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957],\n",
      "         [ 0.6644,  0.7588,  0.7432,  ..., -0.8835, -0.7734,  0.8957]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726],\n",
      "         [ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726],\n",
      "         [ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726],\n",
      "         ...,\n",
      "         [ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726],\n",
      "         [ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726],\n",
      "         [ 0.7148,  0.7943,  0.7822,  ..., -0.8750, -0.7700,  0.8726]],\n",
      "\n",
      "        [[ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567],\n",
      "         [ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567],\n",
      "         [ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567],\n",
      "         ...,\n",
      "         [ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567],\n",
      "         [ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567],\n",
      "         [ 0.6944,  0.7764,  0.7644,  ..., -0.8102, -0.6932,  0.7567]],\n",
      "\n",
      "        [[ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864],\n",
      "         [ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864],\n",
      "         [ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864],\n",
      "         ...,\n",
      "         [ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864],\n",
      "         [ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864],\n",
      "         [ 0.6337,  0.7387,  0.7292,  ..., -0.5836, -0.4525,  0.4864]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "After ATT:  tensor([[ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930],\n",
      "        [ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930],\n",
      "        [ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930],\n",
      "        ...,\n",
      "        [ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930],\n",
      "        [ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930],\n",
      "        [ 0.1517,  0.1694,  0.1663,  ..., -0.1930, -0.1689,  0.1930]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "After FC:  tensor([[ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612],\n",
      "        [ 1.1378, -1.2612]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([90, 2]) torch.Size([90])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833],\n",
      "        [0.9167, 0.0833]], grad_fn=<SoftmaxBackward>)\n",
      "Ground truth: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "Correct: 82\n",
      "torch.Size([90, 20, 20, 375])\n",
      "input:  torch.Size([90, 20, 20, 375])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-5e14bd1a838b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Run the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-c80e3867f02b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# print(X[0,0,:].float().unsqueeze(1), X[0,1,:].float().unsqueeze(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_per_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# print('Equal:', out[0][0] == out[0][1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-c80e3867f02b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# print(X[0,0,:].float().unsqueeze(1), X[0,1,:].float().unsqueeze(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_per_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# print('Equal:', out[0][0] == out[0][1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a4fe3d744307>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# out = out.reshape(out.size(0), -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cs236781-project/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 488\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Baseline()\n",
    "num_epochs = 200\n",
    "# total_size = len(x_train)\n",
    "# test.assertEqual(total_size, len(y_train))\n",
    "\n",
    "# Preparation\n",
    "dataloader = DataLoader(dataset, batch_size=90)\n",
    "\n",
    "# Loss and optimizer\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Train the model\n",
    "total_step = total_data_size\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    acc = 0\n",
    "    total_size = len(dataset)\n",
    "    for batch_data, batch_labels in tqdm(dataloader):\n",
    "\n",
    "        print(batch_data.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Run the forward pass\n",
    "        output = model(batch_data)\n",
    "        \n",
    "        print(output.shape, batch_labels.shape)\n",
    "        \n",
    "        loss = criterion(output, batch_labels)\n",
    "        \n",
    "        # Backprop and perform optimisation\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Track the accuracy\n",
    "        \n",
    "        \n",
    "        probability = torch.distributions.categorical.Categorical(output)\n",
    "        prediction = probability.sample()\n",
    "        \n",
    "        print('Output:', output)\n",
    "        print('Ground truth:', batch_labels)\n",
    "        print('Prediction:', prediction)\n",
    "        correct = (prediction == batch_labels).sum().item()\n",
    "        print('Correct: {}'.format(correct))\n",
    "        acc += correct\n",
    "                    \n",
    "    acc = acc / (total_size)          \n",
    "    acc_list.append(acc)\n",
    "    print('Epoch [{}/{}], Accuracy: {:.2f}%'\n",
    "          .format(epoch + 1, num_epochs, acc * 100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
