{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from IPython.display import display\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import posixpath\n",
    "import wfdb\n",
    "import pycwt as wavelet\n",
    "from data import WaveletTransform, AFECGDataset\n",
    "from PIL import Image\n",
    "import dsp\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = AFECGDataset(dataset_name, '../data/files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  1397\n"
     ]
    }
   ],
   "source": [
    "images_per_sample = 20\n",
    "total_data_size = dataset.get_len()\n",
    "print(\"Total data size: \", total_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [dataset[i][0] for i in range(total_data_size)]\n",
    "labels = [dataset[i][1] for i in range(total_data_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of one ECG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, label = dataset[0]\n",
    "# print('P-signal: ', samples)\n",
    "# print('Has AF: ', 'Yes' if label == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), size=(256, 256))\n",
    "# image_test = to_wavelet(data[0][0])\n",
    "# transforms.ToPILImage()(test_img.permute(2, 1, 0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data size is 1397\n",
    "# You can choose the data size \n",
    "data_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fmt = '../data/images/sample_{}_win_{}.pt'\n",
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), size=(256, 256))\n",
    "# start = time.time()\n",
    "\n",
    "# skip = 0\n",
    "# for sample_idx in range(data_size):\n",
    "#     sample = data[sample_idx]\n",
    "#     for signal_idx, signal in enumerate(sample):\n",
    "#         filepath = fmt.format(sample_idx, signal_idx)\n",
    "#         if os.path.isfile(filepath):\n",
    "#              # print('Skip {},{}'.format(sample_idx, signal_idx))\n",
    "#             skip += 1\n",
    "#             continue\n",
    "#         new_sample = to_wavelet(signal)\n",
    "#         torch.save(new_sample, filepath)\n",
    "    \n",
    "# end = time.time()\n",
    "# print('Elapsed time: {} ms'.format(1000 * (end - start)))\n",
    "# print('Skipped {} files'.format(skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = []\n",
    "transformed_labels= []\n",
    "\n",
    "for sample_idx in range(data_size):\n",
    "    new_sample = []\n",
    "    for signal_idx in range(20):\n",
    "        img = torch.load(fmt.format(sample_idx, signal_idx))\n",
    "        new_sample.append(img)\n",
    "    transformed_data.append(new_sample)\n",
    "    transformed_labels.append(labels[sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(transformed_data, transformed_labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(ConvNet, self).__init__()\n",
    "                \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(81600, 50)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "        # print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        # print(out.shape)\n",
    "\n",
    "        # out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        # print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=81600, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ConvNet(in_channels=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = x_train[0][0].float()\n",
    "# encoder_cnn = ConvNet()\n",
    "\n",
    "# h = encoder_cnn(x0.permute(2, 0, 1).unsqueeze(0))\n",
    "# print(h.shape)\n",
    "\n",
    "# test.assertEqual(h.dim(), 2)\n",
    "# test.assertSequenceEqual(h.shape, (1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvNet()\n",
    "# num_epochs = 100\n",
    "# total_size = len(x_train)\n",
    "# test.assertEqual(total_size, len(y_train))\n",
    "\n",
    "# # Loss and optimizer\n",
    "# learning_rate = 0.001\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Train the model\n",
    "# total_step = len(x_train)\n",
    "# loss_list = []\n",
    "# acc_list = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     acc = 0\n",
    "#     for idx, (samples, label) in enumerate(zip(x_train, y_train)):\n",
    "#         label = torch.tensor([label]).long()\n",
    "#         for image in samples:\n",
    "            \n",
    "#             # Run the forward pass\n",
    "#             output = model(image.float().permute(2, 0, 1).unsqueeze(0))\n",
    "#             loss = criterion(output, label)\n",
    "#             loss_list.append(loss.item())\n",
    "            \n",
    "#             # Backprop and perform Adam optimisation\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             # Track the accuracy\n",
    "#             _, predicted = torch.max(output.data, 1)\n",
    "#             correct = (predicted == label).sum().item()\n",
    "#             acc += correct\n",
    "                        \n",
    "#     acc = acc / (total_size * 20)          \n",
    "#     acc_list.append(acc)\n",
    "#     print('Epoch [{}/{}], Accuracy: {:.2f}%'\n",
    "#           .format(epoch + 1, num_epochs, acc * 100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_gates):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.bi_grus = torch.nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_gates,\n",
    "                                    batch_first=False, bidirectional=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output, hn = self.bi_grus(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRNN(\n",
       "  (bi_grus): GRU(50, 50, num_layers=20, bidirectional=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(BRNN(50, 50, images_per_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations:\n",
    "\n",
    "* $Y = \\left[ y_1, \\ldots, y_T \\right]$ – the input matrix of size $\\left( N \\times T \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $w_\\mathrm{att}$ – The parameters of the attention model, of size $\\left( N \\times 1 \\right)$, where $N$ is the number of features in a single output vector of the BRNN\n",
    "\n",
    "* $\\alpha$ – The attention weights, given as $\\alpha = \\mathrm{softmax} \\left( w_\\mathrm{att}^T Y \\right)$. This is an element-wise softmax, where the output size of $\\alpha$ is $\\left( 1 \\times T \\right)$\n",
    "\n",
    "* $h_\\mathrm{att}$ – Output of the attention mechanism, given by $h_\\mathrm{att} = Y \\alpha^T$, of size $\\left( N \\times 1 \\right)$, i.e. a vector of $N$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxAttention(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SoftmaxAttention, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, input_size))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X [T x N]\n",
    "        # weight [N x 1]\n",
    "        print('X: ', X)\n",
    "        alignment_scores = X.matmul(self.weight.t())\n",
    "        print('AS: ', alignment_scores)\n",
    "        # print('wT: ', self.weight.t().shape)\n",
    "        # print('AS: ', alignment_scores.shape)\n",
    "        # alpha [T x 1]\n",
    "        attn_weights = nn.functional.softmax(alignment_scores, dim=1)\n",
    "        print('ATT: ', attn_weights)\n",
    "        # print('X: ', X.shape)\n",
    "        # h_att [1 x N]\n",
    "        return torch.matmul(attn_weights.transpose(0, 1), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "        lst = []\n",
    "        for i in range(images_per_sample):\n",
    "            \n",
    "            lst.append(ConvNet())\n",
    "            self.add_module('conv{}'.format(i), lst[i])\n",
    "            \n",
    "        self.cnn_layers = lst\n",
    "        self.brnn = BRNN(50, 50, images_per_sample)\n",
    "        self.attention = SoftmaxAttention(100)\n",
    "        self.fc = nn.Linear(100, 2)\n",
    "\n",
    "\n",
    "    def forward(self, X):        \n",
    "        out = [self.cnn_layers[i](X[i].float().permute(2, 0, 1).unsqueeze(0)) for i in range(images_per_sample)]\n",
    "        out = torch.cat(out).unsqueeze(1)\n",
    "        # print('After CNN: ', out)\n",
    "        out = self.brnn(out)\n",
    "        # print('After BRNN: ', out)\n",
    "        out = self.attention(out.squeeze(1))\n",
    "        # print('After ATT: ', out)\n",
    "        out = self.fc(out)\n",
    "        # print('After FC: ', out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Baseline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([[ 0.1308, -0.0136, -0.0275,  ..., -0.1416, -0.1041, -0.0101],\n",
      "        [ 0.1920, -0.0251, -0.0490,  ..., -0.1475, -0.0886, -0.0065],\n",
      "        [ 0.2208, -0.0303, -0.0652,  ..., -0.1499, -0.0769, -0.0043],\n",
      "        ...,\n",
      "        [ 0.2620, -0.0344, -0.0927,  ..., -0.0459,  0.0037,  0.0181],\n",
      "        [ 0.2445, -0.0479, -0.0944,  ..., -0.0157,  0.0058,  0.0228],\n",
      "        [ 0.2149, -0.0623, -0.1005,  ...,  0.0065,  0.0056,  0.0230]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "AS:  tensor([[-0.1875],\n",
      "        [-0.2037],\n",
      "        [-0.2230],\n",
      "        [-0.2416],\n",
      "        [-0.2569],\n",
      "        [-0.2678],\n",
      "        [-0.2742],\n",
      "        [-0.2769],\n",
      "        [-0.2765],\n",
      "        [-0.2738],\n",
      "        [-0.2691],\n",
      "        [-0.2629],\n",
      "        [-0.2554],\n",
      "        [-0.2470],\n",
      "        [-0.2380],\n",
      "        [-0.2286],\n",
      "        [-0.2180],\n",
      "        [-0.2036],\n",
      "        [-0.1792],\n",
      "        [-0.1319]], grad_fn=<MmBackward>)\n",
      "ATT:  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-0.1081, -0.8149]], grad_fn=<AddmmBackward>) tensor([0])\n",
      "X:  tensor([[ 0.1397, -0.0549, -0.0574,  ..., -0.0313, -0.2129, -0.1438],\n",
      "        [ 0.2044, -0.1114, -0.1032,  ..., -0.0346, -0.2112, -0.1581],\n",
      "        [ 0.2349, -0.1592, -0.1371,  ..., -0.0363, -0.2115, -0.1689],\n",
      "        ...,\n",
      "        [ 0.2869, -0.2972, -0.1745,  ..., -0.0581, -0.0772, -0.0480],\n",
      "        [ 0.2721, -0.2835, -0.1660,  ..., -0.0421, -0.0455, -0.0203],\n",
      "        [ 0.2450, -0.2607, -0.1615,  ..., -0.0208, -0.0168,  0.0018]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "AS:  tensor([[-0.1886],\n",
      "        [-0.2122],\n",
      "        [-0.2374],\n",
      "        [-0.2589],\n",
      "        [-0.2741],\n",
      "        [-0.2825],\n",
      "        [-0.2852],\n",
      "        [-0.2834],\n",
      "        [-0.2787],\n",
      "        [-0.2720],\n",
      "        [-0.2642],\n",
      "        [-0.2554],\n",
      "        [-0.2461],\n",
      "        [-0.2360],\n",
      "        [-0.2250],\n",
      "        [-0.2125],\n",
      "        [-0.1966],\n",
      "        [-0.1740],\n",
      "        [-0.1379],\n",
      "        [-0.0763]], grad_fn=<MmBackward>)\n",
      "ATT:  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 5.9234, -4.5478]], grad_fn=<AddmmBackward>) tensor([0])\n",
      "X:  tensor([[ 0.1470, -0.0768, -0.0720,  ...,  0.0132, -0.2697, -0.2160],\n",
      "        [ 0.2143, -0.1557, -0.1294,  ...,  0.0077, -0.2735, -0.2382],\n",
      "        [ 0.2458, -0.2234, -0.1715,  ...,  0.0039, -0.2781, -0.2541],\n",
      "        ...,\n",
      "        [ 0.3006, -0.4004, -0.2181,  ..., -0.0661, -0.1192, -0.0820],\n",
      "        [ 0.2878, -0.3783, -0.2054,  ..., -0.0575, -0.0722, -0.0425],\n",
      "        [ 0.2629, -0.3426, -0.1958,  ..., -0.0362, -0.0282, -0.0091]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "AS:  tensor([[-0.1898],\n",
      "        [-0.2151],\n",
      "        [-0.2413],\n",
      "        [-0.2624],\n",
      "        [-0.2761],\n",
      "        [-0.2825],\n",
      "        [-0.2829],\n",
      "        [-0.2791],\n",
      "        [-0.2727],\n",
      "        [-0.2648],\n",
      "        [-0.2563],\n",
      "        [-0.2474],\n",
      "        [-0.2381],\n",
      "        [-0.2282],\n",
      "        [-0.2172],\n",
      "        [-0.2039],\n",
      "        [-0.1860],\n",
      "        [-0.1596],\n",
      "        [-0.1175],\n",
      "        [-0.0475]], grad_fn=<MmBackward>)\n",
      "ATT:  tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 9.0454, -6.4817]], grad_fn=<AddmmBackward>) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "model = Baseline()\n",
    "num_epochs = 5\n",
    "total_size = len(x_train)\n",
    "test.assertEqual(total_size, len(y_train))\n",
    "\n",
    "# Loss and optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = total_size\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    acc = 0\n",
    "    for idx, (samples, label) in enumerate(zip(x_train, y_train)):\n",
    "        label = torch.tensor([label]).long()\n",
    "\n",
    "        # Run the forward pass\n",
    "        output = model(samples)\n",
    "        print(output, label)\n",
    "        loss = criterion(output, label)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Track the accuracy\n",
    "        prediction = nn.functional.softmax(output, dim=0).argmax(dim=0)\n",
    "        correct = (prediction == label).sum().item()\n",
    "        acc += correct\n",
    "                    \n",
    "    acc = acc / (total_size)          \n",
    "    acc_list.append(acc)\n",
    "    print('Epoch [{}/{}], Accuracy: {:.2f}%'\n",
    "          .format(epoch + 1, num_epochs, acc * 100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
