{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & General Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from IPython.display import display\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import posixpath\n",
    "import wfdb\n",
    "import pycwt as wavelet\n",
    "from data import WaveletTransform, AFECGDataset\n",
    "from PIL import Image\n",
    "import dsp\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'afdb'\n",
    "dataset = AFECGDataset(dataset_name, '../data/files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  1397\n"
     ]
    }
   ],
   "source": [
    "total_data_size = dataset.get_len()\n",
    "print(\"Total data size: \", total_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [dataset[i][0] for i in range(total_data_size)]\n",
    "labels = [dataset[i][1] for i in range(total_data_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of one ECG sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, label = dataset[0]\n",
    "# print('P-signal: ', samples)\n",
    "# print('Has AF: ', 'Yes' if label == 1 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_wavelet = WaveletTransform(wavelet.Morlet(6), size=(256, 256))\n",
    "# image_test = to_wavelet(data[0][0])\n",
    "# transforms.ToPILImage()(test_img.permute(2, 1, 0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data size is 1397\n",
    "# You can choose the data size \n",
    "data_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 41354.79474067688 ms\n"
     ]
    }
   ],
   "source": [
    "fmt = '../data/images/sample_{}_win_{}.pt'\n",
    "to_wavelet = WaveletTransform(wavelet.Morlet(6), size=(256, 256))\n",
    "start = time.time()\n",
    "\n",
    "for sample_idx in range(data_size):\n",
    "    sample = data[sample_idx]\n",
    "    for signal_idx, signal in enumerate(sample):\n",
    "        new_sample = to_wavelet(signal)\n",
    "        torch.save(new_sample, fmt.format(sample_idx, signal_idx))\n",
    "    \n",
    "end = time.time()\n",
    "print('Elapsed time: {} ms'.format(1000 * (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = []\n",
    "transformed_labels= []\n",
    "\n",
    "for sample_idx in range(data_size):\n",
    "    new_sample = []\n",
    "    for signal_idx in range(20):\n",
    "        img = torch.load(fmt.format(sample_idx, signal_idx))\n",
    "        new_sample.append(img)\n",
    "    transformed_data.append(new_sample)\n",
    "    transformed_labels.append(labels[sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(transformed_data, transformed_labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(ConvNet, self).__init__()\n",
    "                \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(3,21)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(10, 10, kernel_size=(4,21)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(81600, 50)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "        print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        print(out.shape)\n",
    "\n",
    "        # out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        print(out.shape)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(4, 21), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=81600, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ConvNet(in_channels=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 10, 254, 236])\n",
      "torch.Size([1, 10, 126, 108])\n",
      "torch.Size([1, 10, 123, 88])\n",
      "torch.Size([1, 10, 120, 68])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "x0 = x_train[0][0].float()\n",
    "encoder_cnn = ConvNet()\n",
    "\n",
    "h = encoder_cnn(x0.permute(2, 0, 1).unsqueeze(0))\n",
    "print(h.shape)\n",
    "\n",
    "test.assertEqual(h.dim(), 2)\n",
    "test.assertSequenceEqual(h.shape, (1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "train_loader = (x_train, y_train)\n",
    "num_epochs = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    # for i, (images, labels) in enumerate(train_loader):\n",
    "    image, label = x_train, y_train\n",
    "    \n",
    "    # Run the forward pass\n",
    "    \n",
    "    print(image.shape)\n",
    "    \n",
    "    \n",
    "    # outputs = model(images)\n",
    "    \n",
    "    \n",
    "#     print(outputs)\n",
    "    \n",
    "    \n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss_list.append(loss.item())\n",
    "\n",
    "#         # Backprop and perform Adam optimisation\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#         # Track the accuracy\n",
    "#     total = labels.size(0)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     correct = (predicted == labels).sum().item()\n",
    "#     acc_list.append(correct / total)\n",
    "\n",
    "#     if (i + 1) % 100 == 0:\n",
    "#         print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "#                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "#                           (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=225, criterion='gini', min_samples_leaf=1, min_samples_split=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Test results: \")\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "y_pred = rnd_clf.predict(df_test)\n",
    "print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
